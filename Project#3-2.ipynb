{"nbformat": 4, "nbformat_minor": 5, "metadata": {"language_info": {"name": "python", "version": "3.10"}, "kernelspec": {"name": "python3", "display_name": "Python 3"}}, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Multilayer Information Diffusion Simulator\n", "---\n", "\n", "This notebook implements a **Python-based simulator** for studying the impact of:\n", "\n", "- Intra-layer clustering (via triangle formation),\n", "- Multilayer (multiplex) structure, and\n", "- Edge-based vs triangle-based diffusion\n", "\n", "on **information diffusion dynamics in complex networks**.\n", "\n", "It is designed to be consistent with the experimental setting described in the manuscript:\n", "\n", "- Multilayer / multiplex complex network (e.g., Higgs Twitter, Citation network),\n", "- Clustering controlled using an m-PageRank\u2013based centrality,\n", "- Diffusion through **single edges** and **triangular motifs**,\n", "- Comparison of non-clustered (NN), semi-clustered (NC), and fully clustered (CC) configurations,\n", "- Estimation of diffusion thresholds and final adoption size \\(S(T)\\) as a function of transmissibility \\(T\\).\n", "\n", "> **Note:**  \n", "> The real Higgs and Citation datasets are not bundled here.  \n", "> Instead, this notebook provides a *generic, configurable simulator* that you can plug real data into (e.g., after constructing a NetworkX graph from your datasets).\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# 0. Basic setup and imports\n", "\n", "import math\n", "import random\n", "from collections import defaultdict, deque\n", "from typing import Dict, List, Tuple, Set\n", "\n", "import networkx as nx\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "random.seed(42)\n", "np.random.seed(42)\n", "\n", "print(\"NetworkX version:\", nx.__version__)\n"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Helper utilities\n", "\n", "These helpers provide:\n", "\n", "- Construction of a *synthetic multiplex network* (two layers) mimicking degree and clustering levels.\n", "- Computation of a **multilayer PageRank (m-PageRank)** centrality.\n", "- Controlled creation / destruction of triangles to adjust the clustering coefficient while preserving (approximately) the degree distribution.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# 1.1 Build a synthetic multiplex graph\n", "#\n", "# We use the same node set for both layers, but different edge sets.\n", "# Each layer is a NetworkX graph stored in a dict: {layer_id: G_layer}.\n", "\n", "def generate_multiplex_network(\n", "    n: int = 2000,\n", "    avg_degree_layer1: float = 4.0,\n", "    avg_degree_layer2: float = 6.0,\n", ") -> Dict[int, nx.Graph]:\n", "    \"\"\"Generate a simple 2-layer multiplex network using configuration-like graphs.\n", "\n", "    Layer 1: relatively sparse\n", "    Layer 2: denser (to mimic high-activity channels)\n", "    \"\"\"\n", "    # Use a simple expected-degree model\n", "    def _gnp(n, avg_degree):\n", "        p = avg_degree / (n - 1)\n", "        G = nx.fast_gnp_random_graph(n, p, seed=random.randint(0, 10**9))\n", "        # retain the largest connected component\n", "        if not nx.is_connected(G):\n", "            giant = max(nx.connected_components(G), key=len)\n", "            G = G.subgraph(giant).copy()\n", "        return G\n", "\n", "    G1 = _gnp(n, avg_degree_layer1)\n", "    G2 = _gnp(n, avg_degree_layer2)\n", "    print(\"Layer 1: nodes =\", G1.number_of_nodes(), \"edges =\", G1.number_of_edges())\n", "    print(\"Layer 2: nodes =\", G2.number_of_nodes(), \"edges =\", G2.number_of_edges())\n", "    return {0: G1, 1: G2}\n", "\n", "\n", "# Example: generate a small multiplex for quick experimentation\n", "layers = generate_multiplex_network(n=1000, avg_degree_layer1=4.0, avg_degree_layer2=6.0)\n"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# 1.2 Multilayer PageRank (m-PageRank)\n", "#\n", "# m-PageRank is defined here as an aggregation of PageRank scores\n", "# computed separately on each layer. More sophisticated definitions\n", "# (e.g., explicit inter-layer edges) can be added as needed.\n", "\n", "def m_pagerank(\n", "    layers: Dict[int, nx.Graph],\n", "    alpha: float = 0.85,\n", "    weight_by_layer: Dict[int, float] = None,\n", ") -> Dict[int, float]:\n", "    \"\"\"Compute a simple multilayer PageRank by aggregating per-layer PageRank scores.\n", "\n", "    Args:\n", "        layers: dict mapping layer_id -> Graph (all with the same node set).\n", "        alpha: PageRank damping factor.\n", "        weight_by_layer: optional weights for each layer_id (default: uniform).\n", "\n", "    Returns:\n", "        dict: node -> m-PageRank score (normalized to sum=1).\n", "    \"\"\"\n", "    if weight_by_layer is None:\n", "        weight_by_layer = {lid: 1.0 for lid in layers}\n", "\n", "    node_scores = defaultdict(float)\n", "    for lid, G in layers.items():\n", "        if G.number_of_nodes() == 0:\n", "            continue\n", "        pr = nx.pagerank(G, alpha=alpha)\n", "        w = weight_by_layer.get(lid, 1.0)\n", "        for v, score in pr.items():\n", "            node_scores[v] += w * score\n", "\n", "    # Normalize\n", "    total = sum(node_scores.values())\n", "    if total > 0:\n", "        for v in list(node_scores.keys()):\n", "            node_scores[v] /= total\n", "    return dict(node_scores)\n", "\n", "\n", "mpr = m_pagerank(layers)\n", "print(\"Computed m-PageRank for\", len(mpr), \"nodes.\")\n", "\n", "# Show basic stats\n", "vals = np.array(list(mpr.values()))\n", "print(\"m-PageRank: min =\", vals.min(), \"max =\", vals.max(), \"mean =\", vals.mean())\n"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# 1.3 Triangle utilities\n", "\n", "def count_triangles(G: nx.Graph) -> int:\n", "    \"\"\"Return total number of triangles in an undirected graph.\"\"\"\n", "    tri_dict = nx.triangles(G)\n", "    return sum(tri_dict.values()) // 3\n", "\n", "\n", "def average_clustering(G: nx.Graph) -> float:\n", "    return nx.average_clustering(G)\n", "\n", "\n", "for lid, G in layers.items():\n", "    print(f\"Layer {lid}: C = {average_clustering(G):.4f}, triangles = {count_triangles(G)}\")\n"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# 1.4 Increase or decrease clustering via triangle closing or edge rewiring\n", "\n", "def increase_clustering(\n", "    G: nx.Graph,\n", "    mpr: Dict[int, float],\n", "    budget_edges: int = 1000,\n", "    close_probability: float = 0.5,\n", ") -> nx.Graph:\n", "    \"\"\"Increase clustering by preferential triangle closing around high-mPR nodes.\n", "\n", "    - For high-mPR nodes, we look at non-adjacent neighbor pairs and optionally\n", "      add an edge to form a triangle.\n", "    - The number of new edges is limited by budget_edges.\n", "    \"\"\"\n", "    G = G.copy()\n", "    nodes_sorted = sorted(G.nodes(), key=lambda v: -mpr.get(v, 0.0))\n", "    added = 0\n", "\n", "    for v in nodes_sorted:\n", "        if added >= budget_edges:\n", "            break\n", "        nbrs = list(G.neighbors(v))\n", "        if len(nbrs) < 2:\n", "            continue\n", "        # Try random pairs of neighbors\n", "        random.shuffle(nbrs)\n", "        for i in range(len(nbrs)):\n", "            if added >= budget_edges:\n", "                break\n", "            for j in range(i + 1, len(nbrs)):\n", "                u, w = nbrs[i], nbrs[j]\n", "                if not G.has_edge(u, w) and random.random() < close_probability:\n", "                    G.add_edge(u, w)\n", "                    added += 1\n", "                    if added >= budget_edges:\n", "                        break\n", "    return G\n", "\n", "\n", "def decrease_clustering(\n", "    G: nx.Graph,\n", "    budget_swaps: int = 1000,\n", ") -> nx.Graph:\n", "    \"\"\"Decrease clustering while approximately preserving degree distribution.\n", "\n", "    Uses double-edge swaps to randomize the graph, which typically lowers clustering.\n", "    \"\"\"\n", "    G = G.copy()\n", "    if G.number_of_edges() < 2:\n", "        return G\n", "    # Perform edge swaps\n", "    nx.double_edge_swap(G, nswap=budget_swaps, max_tries=5 * budget_swaps)\n", "    return G\n"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Construct NN, NC, and CC configurations\n", "\n", "We now construct three variants of the multiplex network:\n", "\n", "- **NN (Non-clustered)** \u2014 low clustering in both layers  \n", "- **NC (Semi-clustered)** \u2014 one clustered layer, one non-clustered  \n", "- **CC (Fully clustered)** \u2014 both layers highly clustered  \n", "\n", "Clustering is controlled using:\n", "\n", "- **m-PageRank** to prioritize influential nodes for triangle closing,\n", "- **Edge swaps** to reduce clustering while preserving degrees.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["def build_NN_NC_CC(\n", "    layers: Dict[int, nx.Graph],\n", "    mpr: Dict[int, float],\n", "    inc_budget: int = 2000,\n", "    dec_budget: int = 4000,\n", "):\n", "    \"\"\"Build NN, NC, CC configurations from base layers.\n", "\n", "    Returns:\n", "        configs: dict with keys 'NN', 'NC', 'CC', each a dict layer_id -> Graph\n", "    \"\"\"\n", "    base_layers = {lid: G.copy() for lid, G in layers.items()}\n", "\n", "    # First, create a low-clustered baseline for each layer\n", "    low_layers = {lid: decrease_clustering(G, budget_swaps=dec_budget) for lid, G in base_layers.items()}\n", "\n", "    # Then, create high-clustered versions using mPR-based triangle closing\n", "    high_layers = {lid: increase_clustering(G, mpr, budget_edges=inc_budget) for lid, G in base_layers.items()}\n", "\n", "    NN = {0: low_layers[0].copy(), 1: low_layers[1].copy()}\n", "    NC = {0: high_layers[0].copy(), 1: low_layers[1].copy()}\n", "    CC = {0: high_layers[0].copy(), 1: high_layers[1].copy()}\n", "\n", "    return {\"NN\": NN, \"NC\": NC, \"CC\": CC}\n", "\n", "\n", "configs = build_NN_NC_CC(layers, mpr, inc_budget=1500, dec_budget=3000)\n", "\n", "for name, cfg in configs.items():\n", "    print(f\"Configuration {name}:\")\n", "    for lid, G in cfg.items():\n", "        print(f\"  Layer {lid}: C = {average_clustering(G):.4f}, triangles = {count_triangles(G)}\")\n", "    print()\n"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Diffusion models\n", "\n", "We now define:\n", "\n", "- **Edge-based independent cascade diffusion** (single-edge contagion),\n", "- **Triangle-based diffusion**, where activation is driven by triangular motifs.\n", "\n", "For triangle-based diffusion, we adopt a simple but interpretable mechanism:\n", "\n", "- Activation can occur via **either**:\n", "  - a direct infected neighbor through an edge with probability \\(T_\\alpha\\), or\n", "  - a *reinforced* influence when two infected neighbors share a triangle with a susceptible node, modeled by a higher effective probability \\(T_\\beta\\).\n", "\n", "This captures the intuition of the analytical functions \\(h_\\alpha^t(x)\\) and \\(h_\\beta^t(x)\\) that separately account for single-edge and triangle contributions.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# 3.1 Extract triangles and triangle adjacency structure\n", "\n", "def enumerate_triangles(G: nx.Graph) -> List[Tuple[int, int, int]]:\n", "    \"\"\"Return list of triangles as node triples (u, v, w).\"\"\"\n", "    # Use built-in algorithm\n", "    triangles = []\n", "    # networkx.cycle_basis can be used, but nx.triangles is faster\n", "    # We'll build from node-wise neighbor lists\n", "    nodes = list(G.nodes())\n", "    node_index = {v: i for i, v in enumerate(nodes)}\n", "    # Use a simple algorithm through adjacency\n", "    for v in nodes:\n", "        nbrs = list(G.neighbors(v))\n", "        nbrs_sorted = sorted(nbrs, key=lambda x: node_index[x])\n", "        for i in range(len(nbrs_sorted)):\n", "            for j in range(i + 1, len(nbrs_sorted)):\n", "                u, w = nbrs_sorted[i], nbrs_sorted[j]\n", "                if G.has_edge(u, w):\n", "                    tri = tuple(sorted((u, v, w), key=lambda x: node_index[x]))\n", "                    triangles.append(tri)\n", "    # Remove duplicates\n", "    triangles = list(dict.fromkeys(triangles))\n", "    return triangles\n", "\n", "\n", "def build_triangle_index(triangles: List[Tuple[int, int, int]]):\n", "    \"\"\"Build mapping from node to triangles containing it.\"\"\"\n", "    tri_index = defaultdict(list)\n", "    for idx, tri in enumerate(triangles):\n", "        for v in tri:\n", "            tri_index[v].append(idx)\n", "    return tri_index\n"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# 3.2 Edge-based independent cascade diffusion\n", "\n", "def simulate_edge_diffusion(\n", "    G: nx.Graph,\n", "    seeds: List[int],\n", "    T: float,\n", "    max_steps: int = 1000,\n", ") -> Set[int]:\n", "    \"\"\"Independent cascade on edges with transmissibility T.\n", "\n", "    Returns:\n", "        infected: set of activated nodes at the end of the process.\n", "    \"\"\"\n", "    infected = set(seeds)\n", "    newly_infected = set(seeds)\n", "\n", "    step = 0\n", "    while newly_infected and step < max_steps:\n", "        next_new = set()\n", "        for u in newly_infected:\n", "            for v in G.neighbors(u):\n", "                if v not in infected:\n", "                    if random.random() < T:\n", "                        infected.add(v)\n", "                        next_new.add(v)\n", "        newly_infected = next_new\n", "        step += 1\n", "    return infected\n"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# 3.3 Triangle-based diffusion with reinforcement\n", "\n", "def simulate_triangle_diffusion(\n", "    G: nx.Graph,\n", "    seeds: List[int],\n", "    T_alpha: float,\n", "    T_beta: float,\n", "    max_steps: int = 1000,\n", ") -> Set[int]:\n", "    \"\"\"Diffusion with both single-edge (T_alpha) and triangle-reinforced (T_beta) contagion.\n", "\n", "    Mechanism:\n", "    - For each susceptible node v and each infected neighbor u:\n", "      - Try infection with probability T_alpha.\n", "    - Additionally, if v is part of any triangle (v, u, w) where both u and w\n", "      are infected, we attempt infection with probability T_beta.\n", "\n", "    Returns:\n", "        infected: set of activated nodes at the end of the process.\n", "    \"\"\"\n", "    triangles = enumerate_triangles(G)\n", "    tri_index = build_triangle_index(triangles)\n", "\n", "    infected = set(seeds)\n", "    newly_infected = set(seeds)\n", "\n", "    step = 0\n", "    while newly_infected and step < max_steps:\n", "        next_new = set()\n", "\n", "        # Edge-based trials\n", "        for u in newly_infected:\n", "            for v in G.neighbors(u):\n", "                if v not in infected:\n", "                    if random.random() < T_alpha:\n", "                        infected.add(v)\n", "                        next_new.add(v)\n", "\n", "        # Triangle-based reinforcement\n", "        # For every susceptible v, check triangles containing v\n", "        for v in list(G.nodes()):\n", "            if v in infected:\n", "                continue\n", "            in_tris = tri_index.get(v, [])\n", "            if not in_tris:\n", "                continue\n", "            # If at least two nodes in a triangle are infected, try reinforced infection\n", "            infected_neigh_pairs_found = False\n", "            for tri_id in in_tris:\n", "                tri = triangles[tri_id]\n", "                others = [x for x in tri if x != v]\n", "                if len(others) != 2:\n", "                    continue\n", "                u, w = others\n", "                if u in infected and w in infected:\n", "                    infected_neigh_pairs_found = True\n", "                    if random.random() < T_beta:\n", "                        infected.add(v)\n", "                        next_new.add(v)\n", "                        break\n", "            if infected_neigh_pairs_found and v in infected:\n", "                # Already infected in this step, no need to continue checking\n", "                continue\n", "\n", "        newly_infected = next_new\n", "        step += 1\n", "\n", "    return infected\n"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Experimental pipeline\n", "\n", "We now define an experiment driver to:\n", "\n", "- Select a configuration (**NN**, **NC**, or **CC**),\n", "- Run diffusion for a range of transmissibility values \\(T\\),\n", "- Estimate the final adoption size \\(S(T)\\) and an empirical diffusion threshold.\n", "\n", "### 4.1 Final adoption size and empirical threshold\n", "\n", "For a given \\(T\\), we define:\n", "\n", "- \\( S(T) = \\frac{|A(T)|}{N} \\), where \\(A(T)\\) is the set of activated nodes.\n", "\n", "A simple empirical **threshold** can be defined as the smallest \\(T\\) where:\n", "\n", "- \\( S(T) \\ge S_{\\min} \\), e.g. \\(S_{\\min} = 0.1\\) (10% adoption),\n", "- You can adjust this according to your theoretical threshold from the PGF analysis.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["def run_diffusion_curve(\n", "    G: nx.Graph,\n", "    T_values: List[float],\n", "    mode: str = \"edge\",\n", "    T_alpha: float = None,\n", "    T_beta: float = None,\n", "    num_seeds: int = 5,\n", "    num_reps: int = 5,\n", "):\n", "    \"\"\"Run diffusion for each T and return S(T) for chosen mode.\n", "\n", "    mode: 'edge' or 'triangle'\n", "    \"\"\"\n", "    n = G.number_of_nodes()\n", "    nodes = list(G.nodes())\n", "\n", "    results = []\n", "    for T in T_values:\n", "        sizes = []\n", "        for _ in range(num_reps):\n", "            seeds = random.sample(nodes, num_seeds)\n", "            if mode == \"edge\":\n", "                infected = simulate_edge_diffusion(G, seeds, T=T)\n", "            elif mode == \"triangle\":\n", "                Ta = T if T_alpha is None else T_alpha\n", "                Tb = min(1.0, T * 1.5) if T_beta is None else T_beta\n", "                infected = simulate_triangle_diffusion(G, seeds, T_alpha=Ta, T_beta=Tb)\n", "            else:\n", "                raise ValueError(\"Unknown mode: \" + mode)\n", "            sizes.append(len(infected) / n)\n", "        results.append(np.mean(sizes))\n", "    return np.array(results)\n", "\n", "\n", "def estimate_threshold(T_values: List[float], S_values: np.ndarray, S_min: float = 0.1):\n", "    \"\"\"Estimate empirical threshold as smallest T with S(T) >= S_min.\"\"\"\n", "    for T, S in zip(T_values, S_values):\n", "        if S >= S_min:\n", "            return T\n", "    return None\n"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 4.2 Example: diffusion vs clustering on NN / NC / CC\n", "\n", "We now:\n", "\n", "- Select the **largest connected component** of each layer in a given configuration,\n", "- Use one of the layers as the diffusion substrate (or you can merge them),\n", "- Compare diffusion curves for:\n", "  - Non-clustered (NN),\n", "  - Semi-clustered (NC),\n", "  - Fully clustered (CC).\n"]}, {"cell_type": "code", "metadata": {}, "source": ["def get_largest_cc(G: nx.Graph) -> nx.Graph:\n", "    if nx.is_connected(G):\n", "        return G.copy()\n", "    giant = max(nx.connected_components(G), key=len)\n", "    return G.subgraph(giant).copy()\n", "\n", "\n", "# Choose which layer to simulate diffusion on (e.g., layer 0)\n", "layer_id_for_diffusion = 0\n", "\n", "T_values = np.linspace(0.0, 1.0, 21)\n", "\n", "curves_edge = {}\n", "curves_tri = {}\n", "thresholds_edge = {}\n", "thresholds_tri = {}\n", "\n", "for name, cfg in configs.items():\n", "    G_layer = get_largest_cc(cfg[layer_id_for_diffusion])\n", "    print(f\"{name}: using layer {layer_id_for_diffusion} with n={G_layer.number_of_nodes()}, \"\n", "          f\"m={G_layer.number_of_edges()}, C={average_clustering(G_layer):.4f}\")\n", "\n", "    # Edge-based diffusion\n", "    S_edge = run_diffusion_curve(\n", "        G_layer, T_values, mode=\"edge\", num_seeds=5, num_reps=5\n", "    )\n", "    curves_edge[name] = S_edge\n", "    thresholds_edge[name] = estimate_threshold(T_values, S_edge, S_min=0.1)\n", "\n", "    # Triangle-based diffusion\n", "    S_tri = run_diffusion_curve(\n", "        G_layer, T_values, mode=\"triangle\", num_seeds=5, num_reps=5\n", "    )\n", "    curves_tri[name] = S_tri\n", "    thresholds_tri[name] = estimate_threshold(T_values, S_tri, S_min=0.1)\n"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 4.3 Plotting diffusion curves\n", "\n", "The following cells visualize:\n", "\n", "- Final adoption size \\(S(T)\\) vs transmissibility \\(T\\) for different clustering configurations,\n", "- Empirical thresholds estimated from the simulation.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Edge-based curves\n", "\n", "plt.figure()\n", "for name, S in curves_edge.items():\n", "    plt.plot(T_values, S, label=f\"{name}\")\n", "plt.xlabel(\"Transmissibility T\")\n", "plt.ylabel(\"Final adoption size S(T)\")\n", "plt.title(\"Edge-based diffusion: S(T) vs T for NN / NC / CC\")\n", "plt.legend()\n", "plt.grid(True)\n", "plt.show()\n", "\n", "print(\"Empirical thresholds (edge-based, S_min=0.1):\")\n", "for name, th in thresholds_edge.items():\n", "    print(f\"  {name}: T_c \u2248 {th}\")\n"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Triangle-based curves\n", "\n", "plt.figure()\n", "for name, S in curves_tri.items():\n", "    plt.plot(T_values, S, label=f\"{name}\")\n", "plt.xlabel(\"Transmissibility T\")\n", "plt.ylabel(\"Final adoption size S(T)\")\n", "plt.title(\"Triangle-based diffusion: S(T) vs T for NN / NC / CC\")\n", "plt.legend()\n", "plt.grid(True)\n", "plt.show()\n", "\n", "print(\"Empirical thresholds (triangle-based, S_min=0.1):\")\n", "for name, th in thresholds_tri.items():\n", "    print(f\"  {name}: T_c \u2248 {th}\")\n"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Higgs-like subset experiment (10,000 nodes)\n", "\n", "This section reproduces the *spirit* of the theoretical validation experiment:\n", "\n", "- Extract a largest weakly connected component (WCC) with approximately:\n", "  - \\(N \\approx 10^4\\) nodes,\n", "  - \\(E \\approx 3.4 \\times 10^4\\) edges.\n", "- Simulate diffusion for:\n", "  - **single-edge mode (h\\_\\alpha-like)**,\n", "  - **triangle-enhanced mode (h\\_\\beta-like)**.\n", "\n", "In practice, you can replace this synthetic graph with the actual Higgs Twitter WCC.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# 5.1 Generate a Higgs-like synthetic network\n", "\n", "def generate_higgs_like_graph(\n", "    N: int = 10_000,\n", "    avg_degree: float = 6.8,  # so E \u2248 N * avg_degree / 2 \u2248 3.4e4\n", ") -> nx.Graph:\n", "    p = avg_degree / (N - 1)\n", "    G = nx.fast_gnp_random_graph(N, p, seed=123)\n", "    # Take largest connected component\n", "    if not nx.is_connected(G):\n", "        giant = max(nx.connected_components(G), key=len)\n", "        G = G.subgraph(giant).copy()\n", "    return G\n", "\n", "\n", "G_higgs_like = generate_higgs_like_graph()\n", "print(\"Higgs-like graph:\",\n", "      \"N =\", G_higgs_like.number_of_nodes(),\n", "      \"E =\", G_higgs_like.number_of_edges(),\n", "      \"C =\", average_clustering(G_higgs_like),\n", "      \"triangles =\", count_triangles(G_higgs_like))\n"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# 5.2 Run S(T) curves for edge-only vs triangle-enhanced diffusion\n", "\n", "T_values_higgs = np.linspace(0.0, 1.0, 21)\n", "\n", "S_edge_higgs = run_diffusion_curve(\n", "    G_higgs_like,\n", "    T_values_higgs,\n", "    mode=\"edge\",\n", "    num_seeds=10,\n", "    num_reps=3,\n", ")\n", "\n", "S_tri_higgs = run_diffusion_curve(\n", "    G_higgs_like,\n", "    T_values_higgs,\n", "    mode=\"triangle\",\n", "    num_seeds=10,\n", "    num_reps=3,\n", ")\n", "\n", "T_edge_th = estimate_threshold(T_values_higgs, S_edge_higgs, S_min=0.1)\n", "T_tri_th = estimate_threshold(T_values_higgs, S_tri_higgs, S_min=0.1)\n", "\n", "print(\"Empirical thresholds on Higgs-like graph (S_min=0.1):\")\n", "print(\"  Edge-based   T_c \u2248\", T_edge_th)\n", "print(\"  Triangle-enh T_c \u2248\", T_tri_th)\n"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# 5.3 Plot S(T) curves for Higgs-like graph\n", "\n", "plt.figure()\n", "plt.plot(T_values_higgs, S_edge_higgs, label=\"Edge-based (h_alpha-like)\")\n", "plt.plot(T_values_higgs, S_tri_higgs, label=\"Triangle-based (h_beta-like)\")\n", "plt.xlabel(\"Transmissibility T\")\n", "plt.ylabel(\"Final adoption size S(T)\")\n", "plt.title(\"Higgs-like WCC: Edge vs Triangle diffusion\")\n", "plt.legend()\n", "plt.grid(True)\n", "plt.show()\n"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Connecting to analytical formulations\n", "\n", "In the article, diffusion through single edges and triangles is described analytically using:\n", "\n", "- Probability generating functions (PGFs),\n", "- Functions \\(h_\\alpha^t(x)\\) and \\(h_\\beta^t(x)\\),\n", "- Jacobian-based stability analysis to derive the epidemic threshold.\n", "\n", "This notebook focuses on the **simulation** side. To integrate your exact analytical model:\n", "\n", "1. Implement functions for \\(h_\\alpha^t(x)\\), \\(h_\\beta^t(x)\\), and the PGFs of the degree and triangle distributions.\n", "2. Compute the Jacobian at the disease-free equilibrium and obtain the theoretical threshold \\(T_c^{(theory)}\\).\n", "3. Compare it to the empirical thresholds estimated here (`estimate_threshold`).\n", "\n", "You can add a new code cell below where you plug in your closed-form expressions\n", "derived in the manuscript.\n"]}]}